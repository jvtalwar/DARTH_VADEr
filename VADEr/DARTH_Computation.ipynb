{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@author: James V. Talwar**<br>\n",
    "\n",
    "# Computing DARTH Scores: VADEr Interpretability  \n",
    "\n",
    "**About**: This notebook serves as a tutorial/template for generating VADEr's paired interpretability metric: **D**irected **A**ttention **R**elevance from **T**ransformer **H**euristics (**DARTH**) scores. Specifically, this notebook can be used to calculate and save DARTH scores for a trained VADEr model, with the only changes needed being to the specified paths below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append('./src/')\n",
    "\n",
    "from VADErData import SNP_Dataset\n",
    "from VADErDataUtils import GenerateChromosomePatchMask\n",
    "from vader import VADEr\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "console = logging.StreamHandler()\n",
    "logger.addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "About: Load configuration from yaml-config path\n",
    "\n",
    "Input(s): path: String corresponding to path to yaml config file for training.\n",
    "'''\n",
    "def LoadConfig(path):\n",
    "    return yaml.load(open(path, 'r'), Loader = yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USER: Update the following paths/parameters below:**\n",
    " - `modelSummaryPath`: Path to the directory of k-checkpointed trained VADEr models (for which this notebook will select the best performing model by validation performance on your specified training config `checkpoint metric`).\n",
    " - `trainingSummaryPath`: Path to the corresponding VADEr training performances (i.e., Training and validation set losses, accuracies, and AUCs).\n",
    " - `configPath`: Path to VADEr config used for model training.\n",
    " - `DARTH_score_write_path`: Path to (existing) directory to which want to write dataset DARTH scores.\n",
    " - `DARTH_score_file_name`: File prefix (not including file extension) for which would like to name DARTH scores for dataset under investigation. Update as desired. Default: \"DARTH_Scores\"\n",
    " - `batchSizeForEvaluation`: The number of samples in a batch. Update this according to your resources.\n",
    " - `number_workers`: The total number of workers to use for dataloading. Update this according to your needs/resources.\n",
    " - `featherPath`: Path to the composite genotype feather file for the dataset under investigation.\n",
    " - `phenoPath`: Path to the phenotype file containing phenotype information for all individuals in the dataset under investigation.\n",
    " - `testSetPath`: Path to the dataset-specific ID file, which contains all the individual IDs for the dataset under investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSummaryPath = #<-- UPDATE WITH RELEVANT PATH \n",
    "trainingSummaryPath = #<-- UPDATE WITH RELEVANT PATH \n",
    "configPath = #<-- UPDATE WITH RELEVANT PATH \n",
    "DARTH_score_write_path = #<-- UPDATE WITH RELEVANT PATH \n",
    "DARTH_score_file_name = \"DARTH_Scores\" #<-- Change if desired; default DARTH score write name\n",
    "\n",
    "config = LoadConfig(configPath)\n",
    "datasetParams = config[\"dataset\"]\n",
    "modelParams = config[\"model_params\"]\n",
    "\n",
    "batchSizeForEvaluation = config[\"train_and_checkpoint\"][\"batch_size\"]//2 #<-- SCALE AS NEEDED GIVEN GPU MEMORY RESOURCES\n",
    "number_workers = 16 #<-- UPDATE AS NEEDED ACCORDING TO AVAILABLE RESOURCES\n",
    "\n",
    "featherPath = #<-- UPDATE WITH RELEVANT PATH \n",
    "phenoPath = #<-- UPDATE WITH RELEVANT PATH \n",
    "testSetPath = #<-- UPDATE WITH RELEVANT PATH "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid age path given: /cellar/users/jtalwar/projects/BetterRiskScores/InSNPtion/Galbatorix/DucksInARow/TrainingSetStatistics/ELLIPSE/TrainingSetAgeStats.pkl\n",
      "   Returning z-scored ages in loader...\n",
      "1607 SNPs exist across the full 5e-4 dataset with INF or NULL values. Removing these now... Unremoved SNP set size is 110292\n",
      "Cleaned SNP set size after removal of invalid SNPs is 108685\n",
      "Filtering SNP set for MAF and genotype consistent SNPs...\n",
      "Cleaned SNP set size after filtering incompatible genotype and MAF discrepancy SNPs is 12017\n",
      "100%|██████████| 1204/1204 [00:00<00:00, 3932.72it/s]\n"
     ]
    }
   ],
   "source": [
    "testDataset = SNP_Dataset(featherFilePath = featherPath,\n",
    "                          phenoFilePath = phenoPath,\n",
    "                          idFilePath = testSetPath, \n",
    "                          snpSubsetPath = datasetParams.get(\"SNP_set\"),\n",
    "                          validMafSnpsPath = datasetParams.get(\"consistent_maf_SNPs\"),\n",
    "                          vaderPatchMappingPath = datasetParams.get(\"patch_mapping_path\"),\n",
    "                          trainingSetAgeStatsPath = datasetParams.get(\"age_train_stats\"), \n",
    "                          sparsePatchThreshold = datasetParams.get(\"sparse_patch_threshold\"),\n",
    "                          enableShifting = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset = testDataset, pin_memory = True, shuffle = False, batch_size = batchSizeForEvaluation, num_workers = number_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify, instantiate, and load best trained VADEr model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best Val_AUC occurs at epoch 32 with value 0.74864\n"
     ]
    }
   ],
   "source": [
    "metric_for_selection = config[\"train_and_checkpoint\"][\"checkpoint_metric\"]\n",
    "summary = pd.read_csv(trainingSummaryPath, sep = \"\\t\", index_col = 0)\n",
    "bestEpoch = summary[metric_for_selection].idxmax()\n",
    "logger.info(f\"Best {metric_for_selection} occurs at epoch {bestEpoch} with value {summary[metric_for_selection].max():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Implementing LEARNABLE CLS token representation.\n",
      "Enabling 8 registers\n",
      "Implementing SwiGLU... correcting mlpDim to 2048 to keep number params consistent\n",
      "Implementing learnable temperature for MHA: True\n",
      "Implementing learnable temperature for MHA: True\n",
      "Implementing learnable temperature for MHA: True\n",
      "Implementing learnable temperature for MHA: True\n",
      "Implementing learnable temperature for MHA: True\n",
      "Implementing learnable temperature for MHA: True\n",
      "Implementing learnable temperature for MHA: True\n",
      "Implementing learnable temperature for MHA: True\n",
      "Implementing learnable temperature for MHA: True\n",
      "Implementing learnable temperature for MHA: True\n",
      "Implementing learnable temperature for MHA: True\n",
      "Implementing learnable temperature for MHA: True\n"
     ]
    }
   ],
   "source": [
    "num_registers = modelParams.get(\"num_registers\")\n",
    "\n",
    "vaderModel = VADEr(patchSizes = testDataset.patchSizes,\n",
    "                   modelDim = modelParams[\"model_dim\"],\n",
    "                   mlpDim = modelParams[\"model_dim\"] * modelParams[\"mlp_scale\"],\n",
    "                   depth = modelParams[\"num_transformer_blocks\"],\n",
    "                   attnHeads = modelParams[\"num_attention_heads\"],\n",
    "                   attnHeadDim = modelParams[\"model_dim\"]//modelParams[\"num_attention_heads\"],\n",
    "                   multitaskOutputs = modelParams[\"prediction_dims\"],\n",
    "                   clumpProjectionDropout = modelParams[\"patch_projection_dropout\"],\n",
    "                   dropout = modelParams[\"model_dropout\"], \n",
    "                   ageInclusion = modelParams[\"age_inclusion\"],\n",
    "                   aggr = modelParams[\"aggregation\"],\n",
    "                   context = modelParams.get(\"cls_representation\"),\n",
    "                   patchProjectionActivation = modelParams[\"non_linear_patch_projection\"],\n",
    "                   patchLayerNorm = modelParams.get(\"patch_layer_norm\"),\n",
    "                   trainingObjective = \"cross_entropy\",\n",
    "                   attention = modelParams.get(\"attention\"),\n",
    "                   numRegisters = num_registers,\n",
    "                   ffActivation = modelParams.get(\"mlp_method\"),\n",
    "                   contrastive_projection_net_dim = None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelPath = os.path.join(modelSummaryPath, f\"VADEr_Epoch_{bestEpoch}.pt\")\n",
    "vaderModel.load_state_dict(torch.load(modelPath)[\"modelStateDict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaderModel.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function (and helper functions) to generate DARTH scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average_Heads(attention, gradient, conjugate = False, **kwargs):\n",
    "    attention_map = attention * gradient #[b, h, n, n]\n",
    "    if conjugate:\n",
    "        attention_map *= -1\n",
    "    attention_map = attention_map.clamp(min = 0).mean(dim = 1) #[b, n, n]\n",
    "    \n",
    "    return attention_map\n",
    "\n",
    "def Self_Attention_Rule(attention_map, relevance_map):\n",
    "    return torch.matmul(attention_map, relevance_map)\n",
    "\n",
    "def Generate_Relevance(model, batch_size, num_tokens, **kwargs):\n",
    "    #Identify number of registers used in VADEr model\n",
    "    try:\n",
    "        num_registers = model.registers.size(1)\n",
    "    except:\n",
    "        num_registers = 0\n",
    "\n",
    "    R = torch.eye(num_tokens, num_tokens).unsqueeze(0).repeat(batch_size, 1, 1).to(device) #[b, n, n]\n",
    "    for block in vaderModel.transformer.blocks:\n",
    "        attention = block[1].get_attention_map().detach()\n",
    "        attention_gradient = block[1].get_attention_gradients()\n",
    "        block[1].reset_attention_attributes()\n",
    "        attention_map = Average_Heads(attention = attention, gradient = attention_gradient, **kwargs)\n",
    "        R += Self_Attention_Rule(attention_map = attention_map, relevance_map = R)\n",
    "    \n",
    "    if num_registers > 0:\n",
    "        return R[:, 0, 1:-num_registers].to(\"cpu\")\n",
    "    \n",
    "    else:\n",
    "        return R[:, 0, 1:].to(\"cpu\")\n",
    "    \n",
    "def Generate_Transformer_Explainability(model, loader, device, mask = None, **kwargs):\n",
    "    model.eval() \n",
    "    \n",
    "    vader_attribution = torch.Tensor()\n",
    "    \n",
    "    if \"conjugate\" in kwargs:\n",
    "        assert kwargs[\"conjugate\"] in {True, False}, \"invalid option for conjugate. conjugate must be in {True, False}.\"\n",
    "        logger.info(f\"DARTH score conjugate status: {kwargs['conjugate']}\")\n",
    "        \n",
    "    for i, (patchBatch, diseaseStatusBatch, ancestryBatch, fHBatch, zAgeBatch) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "        gpuClumpBatch = {k:v.to(device) for k,v in patchBatch.items()} #features\n",
    "        \n",
    "        if vaderModel.includeAge: #including age - need to pass in more than clump dictionary\n",
    "            output = vaderModel(dictOfClumps = gpuClumpBatch, mask = mask, age_batch = zAgeBatch.to(device), extract_attention = True)\n",
    "        else:\n",
    "            output = vaderModel(dictOfClumps = gpuClumpBatch, mask = mask, extract_attention = True)\n",
    "        \n",
    "        #sum logits - dy/dA will then be computed for each element in the batch; logits used for cleaner gradients\n",
    "        z = output[\"disease\"].sum()\n",
    "        \n",
    "        #z = F.sigmoid(output[\"disease\"]).sum() #<-- Sigmoid instead of logits if desired: scales derivative by g(x)*1-g(x)\n",
    "        \n",
    "        z.backward()\n",
    "        \n",
    "        batch_attribution = Generate_Relevance(model = model, \n",
    "                                               batch_size = output['disease'].shape[0], \n",
    "                                               num_tokens = model.transformer.blocks[0][1].get_attention_map().size(-1),\n",
    "                                               **kwargs)\n",
    "        \n",
    "        vader_attribution = torch.cat([vader_attribution, batch_attribution])\n",
    "        \n",
    "        # Clean up to prevent memory buildup\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return vader_attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model attributions:\n",
    "\n",
    " - **Nota Bene**: Given the size of your dataset and your specified `batchSizeForEvaluation`, this computation (in the subsequent cell) may take some time (on the order of hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_patch_attribution = Generate_Transformer_Explainability(model = vaderModel, loader = loader, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save attributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testIDs = pd.read_csv(testSetPath, header = None, dtype = str)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericalOrderedPatches = sorted([int(patch.split(\"p\")[1]) for patch in testDataset.patchSizes])\n",
    "patch_columns = [\"patch\" + str(el) for el in numericalOrderedPatches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_interpretability_df = pd.DataFrame(vader_patch_attribution, index = testIDs, columns = patch_columns)\n",
    "vader_interpretability_df.to_csv(os.path.join(DARTH_score_write_path, f\"{DARTH_score_file_name}.tsv\"), sep = \"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Intersect2.0",
   "language": "python",
   "name": "intersect2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
